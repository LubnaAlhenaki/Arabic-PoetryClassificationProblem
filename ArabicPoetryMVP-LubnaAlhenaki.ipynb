{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import needed Packages\n",
    "\n",
    "#Data Analysis \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Data Pre-processing\n",
    "import re\n",
    "import pyarabic.araby as arabic\n",
    "import pyarabic.araby_const\n",
    "from nltk.corpus import stopwords\n",
    "import string \n",
    "import nltk\n",
    "import arabicnlp\n",
    "from itertools import chain\n",
    "from nltk.tokenize import word_tokenize #pre-processing (toknization)\n",
    "from collections import defaultdict, Counter\n",
    "import tashaphyne.arabic_const as pre_arabic\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "\n",
    "#Modeling\n",
    "\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,cross_validate ,GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score,confusion_matrix,make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "\n",
    "#settings\n",
    "pd.set_option('display.max_colwidth',100000000000)\n",
    "%matplotlib inline\n",
    "# nltk.download('stopwords')\n",
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install arabicnlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arabic Poetry Classification Problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arabic Poetry Classification Workflow Steps:\n",
    "The competition solution workflow goes through six stages described in the [Data Science Solutions book](https://leanpub.com/data-science-solutions).\n",
    "\n",
    "* Problem Definition.\n",
    "* Acquire training and testing data.\n",
    "* Analyze, identify patterns, and explore the data.\n",
    "* Data cleansing\n",
    "* Model, predict and solve the problem.\n",
    "* Results discussion and report.\n",
    "\n",
    "In general , the workflow indicates a general sequence of how each stage may follow the other. However, there are use cases with exceptions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Statement \n",
    "\n",
    "The analysis of Arabic poetic text using machine learning is not an easy task, as the attributes of Arabic\n",
    "poetry differ from that of other Arabic texts. \n",
    "In this project, a classification model built to classify Arabic poetry based on the poet's origin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the Dataset \n",
    "The dataset contains around 11K sample of poems that extend from the 6th century to the present day. This dataset consist of 9 features and 11604 instance. In addition,it included 11594 poems of 591 poets.The total number of words was 1741848(before pre-processing)\n",
    "\n",
    "Moreover, the dataset was scraped from [Adab website]( http://adab.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_df=pd.read_csv('poems_11K_sample.csv')\n",
    "poem_df.shape #check the number of instance and featuers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA) and Pre-Processing \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Data Inspection**\n",
    "* What data type is data?\n",
    "* How many poem does dataset contain?\n",
    "* Inspect the first data point, what does it look like?\n",
    "* How many poem of each category does dataset contain?\n",
    "\n",
    "\n",
    "So, I tried to analyze by describing the data (Take a look into the dataset to understand it).In the following sections, I tried to answer several questions that help me to understand the dataset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "poem_df.head() #viewing the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Which features are available in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Which is the data type of each feature?\n",
    "\n",
    "    From the following results, we observed that:\n",
    "\n",
    "    - Categorical: poem_style, poem_link, poem_text, poem_title, poet_link, poet_name, and poet_cat\n",
    "\n",
    "    - Mixed (Numerical and Categorical): poem_id, and poet_id\n",
    "\n",
    "   Besides, this helps to select the appropriate plots for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_uniques=poem_df.select_dtypes(include='number').nunique()#The number of unique values per numerical feature\n",
    "numerical_uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonnumerical_uniques = poem_df.select_dtypes(exclude='number').nunique()#The number of unique values per nonnumerical feature\n",
    "nonnumerical_uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_df.columns = poem_df.columns.str.strip() #Remove space from the dataframe columns for ease of use in analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 What is the distribution of categorical features? \n",
    "(Statistics summary on the dataset) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_df.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observed that:\n",
    "* Poem_style takes three possible values. 'فصحى' style used by most poets (top='فصحى', freq=11581).\n",
    "* Poet_cat feature as 26 possible values with 33% 'العصر العباسي' (top='العصر العباسي', freq=3836/count=11604).\n",
    "* poem_links are unique across the dataset (count=unique=11604).\n",
    "* 'ابن الرومي' is the most popular Poet_name with around 3%.\n",
    "* Poet_link feature has high ratio (94%) of duplicate values (unique=591)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Is there any null or unknown values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The total and percentages of null values per feature:\\n')\n",
    "missing_data = pd.DataFrame({'Total_Missing': poem_df.isnull().sum(), '%_Missing': (poem_df.isnull().sum()/11604)*100})\n",
    "missing_data\n",
    "## The data is clean, there is no null values in the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "poem_df.poem_style.value_counts() #there is an unknown featuers (-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  In this situation, the cross-tabulation was used to predict the unknown value. The hypothesis was one feature influenced by another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(poem_df.poem_title,poem_df.poem_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " poem_df['poem_style']=poem_df['poem_style'].replace('-','فصحى')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of Poem: {}'.format(len(poem_df.poem_text)))\n",
    "print('Number of poet that appear multiple times: {}'.format(np.sum(poem_df.poem_title.value_counts() > 1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Exploratory Data Analysis (EDA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The observations from the following visualization are:__\n",
    "\n",
    "\n",
    ">1. The poet category (predicted value) is 33% and 10% for العصر العباسي والاندلسي respictivaly. Therefore, like most of the NLP datasets this dataset is seems to be slightly imbalanced, but we're not sure (yet)\n",
    "if this imbalanced will be significant. We’ll come back to this in the modeling section.  \n",
    ">2. 3.4% of the poem was written by ابن الرومي followed 2.8% by أبوالعلاء المعري\t\n",
    "> ( This is reasonable because ابن الرومي were in العصر العباسي origin). \n",
    ">3. 0.1% of poem style were not written in الفصحى\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look into the distribution of each feature\n",
    "\n",
    "def features_distribution(col, ax):\n",
    "    poem_df[col][poem_df[col].notnull()].value_counts().plot(kind='bar', facecolor='y', ax=ax)\n",
    "    ax.set_xlabel('{}'.format(col), fontsize=20)\n",
    "    ax.set_title(\"{} \".format(col), fontsize= 18)\n",
    "    return ax\n",
    "\n",
    "f, ax = plt.subplots(3,3, figsize = (22,15))\n",
    "f.tight_layout(h_pad=9, w_pad=2, rect=[0, 0.03, 1, 0.93])\n",
    "columns = ['poem_id', 'poem_link', 'poem_style', 'poem_text', 'poem_title','poet_cat', 'poet_id', 'poet_link', 'poet_name']\n",
    "\n",
    "\n",
    "counter = 0\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        features_distribution(columns [counter], ax[i][j])\n",
    "        counter += 1\n",
    "feature_plot = plt.suptitle(\"Initial Distributions of features\", fontsize= 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_df.poet_cat.value_counts()[:10].plot(kind='bar');\n",
    "\n",
    "# The dataset comes with 26 labels.The label indicates the poet origin.\n",
    "# Our job is to predict the Arabic poetry based on the poet origin in the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the top 10 poet depending on the number of poem\n",
    "top_poet_name = poem_df.groupby(['poet_name']).size().reset_index(name='counts').sort_values('counts',ascending=False,inplace=False)\n",
    "\n",
    "\n",
    "#plt.style.use('dark_background')\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.set_style(\"darkgrid\", {'axes.grid' : False})\n",
    "sns.barplot(x=top_poet_name.poet_name[:10], y=top_poet_name.counts[:10])\n",
    "plt.title('The Name of the Most Popular Poet ')\n",
    "plt.xlabel(\"Poet Name\", fontsize=15)\n",
    "plt.ylabel(\"Number of Poem\", fontsize=15)\n",
    "plt.xticks(rotation=50)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#How many poem of each category does dataset contain?\n",
    "poem_category = poem_df.groupby(['poet_cat']).agg({'poem_title':['count']}).sort_values([('poem_title', 'count')],ascending=False)\n",
    "#poem_category.plot(kind='bar');\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "sns.set_style(\"darkgrid\", {'axes.grid' : False})\n",
    "sns.barplot(poem_category.index,poem_category[('poem_title', 'count')])\n",
    "\n",
    "plt.title('The Number of poem in Each Category ')\n",
    "plt.xlabel(\"Poet category\", fontsize=15)\n",
    "plt.ylabel(\"Number of Poem\", fontsize=15)\n",
    "plt.xticks(rotation=50)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Data Pre-Processing\n",
    "\n",
    "\n",
    "**Common data cleaning steps on all text:**\n",
    "* Strip Arabic Diacritics\n",
    "* Remove punctuation\n",
    "* Remove numerical values\n",
    "* Remove common non-sensical text (/n)\n",
    "* Strip Elongation\n",
    "* Toknize\n",
    "* Remove stop words\n",
    "\n",
    "**More data cleaning steps after tokenization:**\n",
    "* Normailze\n",
    "* Deal with typos\n",
    "* And more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(text):   #check the numbre of all words before pre-processing  \n",
    "    tex=word_tokenize(text)\n",
    "    number_words = sum(1 for tokens in tex)\n",
    "    return number_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_words=poem_df.poem_text.apply(lambda x:count_words(x)) #total number of poem words = 1741848 before pre-preocessing\n",
    "results_words.sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Remove Punctuations and Special Character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove_punctuations_and_specialCharacter\n",
    "def remove_specialCharacter(text):  \n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub('[‘’“”…]', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt=string.punctuation\n",
    "rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puncs = [\",\",\".\",\"``\",\"''\",\";\",\"?\",\"--\",\"-\",\")\",\"(\",\":\",\"!\",\"...\",\"|\",\"…\",\"،\",\"..\",\"\\\"\",\"؟\"]\n",
    "pun_nltk=list(string.punctuation)\n",
    "allpun= str(puncs+pun_nltk )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 Remove Arabic Diacritics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_diacritics(text):\n",
    "    return arabic.strip_harakat(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7 Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_arabic(text):\n",
    "#     text = re.sub(\"ا\" ,'أ',text)\n",
    "#     text = re.sub(\"ى\", \"ي\", text)\n",
    "#     text = re.sub(\"ؤ\", \"ء\", text)\n",
    "#     text = re.sub(\"ئ\", \"ء\", text)\n",
    "#     text = re.sub(\"ة\", \"ه\", text)\n",
    "#     text = re.sub(\"گ\", \"ك\", text)\n",
    "      text=pre_arabic.LAMALEFAT_PAT.sub(r'%s%s'%(pre_arabic.LAM, pre_arabic.ALEF), text)\n",
    "      text = pre_arabic.ALEFAT_PAT.sub(pre_arabic.ALEF, text) \n",
    "      text=pre_arabic.HAMZAT_PAT.sub(pre_arabic.HAMZA, text)\n",
    "      return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8 Remove Stopwords \n",
    "\n",
    "As can be observed from the following code, the most common words are stop words such as conjunctions, prepositions, and pronouns that should be deleted to prevent their results from having an impact on the classification.\n",
    "\n",
    "I searched and found the largest list of Arabic stop words on [Github](https://github.com/mohataher/arabic-stop-words) so, I prefer to use it rather than NLTK stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking into the most common words in poem text before pre-processing\n",
    "\n",
    "counter = defaultdict(int)\n",
    "for poem in poem_df.poem_text:\n",
    "    for word in word_tokenize(poem):\n",
    "        counter[word] += 1\n",
    "        \n",
    "common_word = Counter(counter)\n",
    "\n",
    "common_word.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arabic_stopwords=stopwords.words('arabic')\n",
    "\n",
    "\n",
    "file = open('/Users/Mony/Desktop/arabic-stop-words/list.txt', 'r')\n",
    "stop_words = file.readlines()\n",
    "file.close()\n",
    "\n",
    "stop_words= [words.strip().split('\\n') for words in stop_words]\n",
    "stop_words=list(chain(*stop_words))\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    tex=word_tokenize(text)\n",
    "    filtered_words = [word for word in tex if word not in stop_words]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9 Remove Repeating Letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repeating_letters(text):\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.10 Remove the Elongation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_elongation(text):\n",
    "    return re.sub(r'[%s]' % pre_arabic.TATWEEL,    '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text=poem_df.copy() #copy contant of the orginal dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poem_text pre-processing\n",
    "\n",
    "clean_text.poem_text=clean_text.poem_text.apply(lambda x:remove_specialCharacter(x))\n",
    "clean_text.poem_text=clean_text.poem_text.apply(lambda x:remove_diacritics(x))\n",
    "clean_text.poem_text=clean_text.poem_text.apply(lambda x:strip_elongation(x))\n",
    "clean_text.poem_text=clean_text.poem_text.apply(lambda x:remove_repeating_letters(x))\n",
    "\n",
    "clean_text.poem_text=clean_text.poem_text.apply(lambda x:normalize_arabic(x))\n",
    "\n",
    "clean_text.poem_text=clean_text.poem_text.apply(lambda x:remove_stopwords(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text.poem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking into the most common words in poem text after pre-processing\n",
    "fdist1 = nltk.FreqDist(word_tokenize(str(clean_text.poem_text)))\n",
    "fdist1.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The total number of poem wordws after pre-processing was 1315585\n",
    "\n",
    "# after_words=clean_text.poem_text.apply(lambda x:count_words(x))\n",
    "# after_words.sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poem_title pre-processing\n",
    "\n",
    "clean_text.poem_title=clean_text.poem_title.apply(lambda x:remove_specialCharacter(x))\n",
    "clean_text.poem_title=clean_text.poem_title.apply(lambda x:remove_diacritics(x))\n",
    "clean_text.poem_title=clean_text.poem_title.apply(lambda x:normalize_arabic(x))\n",
    "clean_text.poem_title=clean_text.poem_title.apply(lambda x:remove_repeating_letters(x))\n",
    "clean_text.poem_title=clean_text.poem_title.apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text.poem_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poet_name pre-processing\n",
    "\n",
    "\n",
    "clean_text.poet_name=clean_text.poet_name.apply(lambda x:remove_specialCharacter(x))\n",
    "clean_text.poet_name=clean_text.poet_name.apply(lambda x:remove_diacritics(x))\n",
    "clean_text.poet_name=clean_text.poet_name.apply(lambda x:normalize_arabic(x))\n",
    "clean_text.poet_name=clean_text.poet_name.apply(lambda x:remove_repeating_letters(x))\n",
    "clean_text.poet_name=clean_text.poet_name.apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text.poet_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poet_cat pre-processing\n",
    "\n",
    "clean_text.poet_cat=clean_text.poet_cat.apply(lambda x:remove_specialCharacter(x))\n",
    "clean_text.poet_cat=clean_text.poet_cat.apply(lambda x:remove_diacritics(x))\n",
    "clean_text.poet_cat=clean_text.poet_cat.apply(lambda x:normalize_arabic(x))\n",
    "clean_text.poet_cat=clean_text.poet_cat.apply(lambda x:remove_repeating_letters(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text.poet_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.11 **Drive new featuer (length of poem text) from poem text featuer that may be useful in the modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length(text):    \n",
    "    '''a function which returns the length of text'''\n",
    "    return len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text['length'] = clean_text['poem_text'].apply(length)\n",
    "clean_text.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text.poet_cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumtions based on data analysis:\n",
    "\n",
    "- Poem_link and Poet_link features may be dropped from the analysis (as it contains high ratio of duplicates (94%)) \n",
    "  and they may not be a correlation between links and poet_cat.\n",
    "- Poem_id and Poet_id may be dropped from dataset as it does not contribute to poet_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4.Converting Text to Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df=clean_text.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Deleting Unnecessary Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df=processed_df.drop(columns={'poem_id', 'poem_link','poet_id', 'poet_link'}) #drop unwanted featuers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.columns #check the remaining features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Dealing with Categorical Values  ( One Hot Encoding and Ordinal Converting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A- poem_style**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df['poem_style']=pd.get_dummies(processed_df.poem_style, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B- poet_cat**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to '\n",
    "الموجز في الشعر العربي، دراسة في العصور المختلفة للشعر العربي'\n",
    "تأليف فالح الحجية، مراجعة وتقديم د.شوقي ضيف' \n",
    "\n",
    "They arranged the time period of poem into the following:\n",
    "\n",
    "* شعر العصر الجاهلي\n",
    "* \"شِعر صدر الإسلام\" شعر العصر الاسلامي \n",
    "* الشعر العباسي \n",
    "* الشعر الاندلسي\n",
    "* الشعر العثماني\n",
    "* الشعر الحديث \n",
    "\n",
    "So, I transformed the Categorical data of string type into numerical values which the model can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df['poet_cat']=processed_df.poet_cat.replace({'العصر الجاهلي':1,'العصر الاسلامي':2,'العصر العباسي':3,'العصر الاندلسي':4,'شعراء العراق والشام':5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The number of classes were reduced from 26 to 6\n",
    "processed_df['poet_cat']=processed_df.poet_cat.replace(dict.fromkeys(['قطر','موريتانيا','افغانستان','الكويت', 'ايران','الاردن','ليبيا','المغرب','تونس','السودان','الجزاءر','البحرين','الامارات','عمان','عمان','اليمن','فلسطين','السعودية','العراق','مصر','لبنان','سوريا'], '6'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed_df.poet_cat.value_counts() #just to check after replacement stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histogram of poem text lenght of each poet category**\n",
    "\n",
    "As we can see the distributions coincides so it better to leave out text length as a feature for predictive modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = processed_df[processed_df['poet_cat'] == 1]\n",
    "data2 = processed_df[processed_df['poet_cat'] == 2]\n",
    "data3 = processed_df[processed_df['poet_cat'] == 3]\n",
    "data4 = processed_df[processed_df['poet_cat'] == 4]\n",
    "data5 = processed_df[processed_df['poet_cat'] == 5]\n",
    "data6 = processed_df[processed_df['poet_cat'] == 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 6.0)\n",
    "bins = 500\n",
    "plt.hist(data1['length'], alpha = 0.6, bins=bins, label='العصر الجاهلي')\n",
    "plt.hist(data2['length'], alpha = 0.8, bins=bins, label='العصر الاسلامي')\n",
    "plt.hist(data3['length'], alpha = 0.4, bins=bins, label='العصر العباسي')\n",
    "plt.hist(data4['length'], alpha = 0.6, bins=bins, label='العصر الاندلسي')\n",
    "plt.hist(data5['length'], alpha = 0.8, bins=bins, label='العراق والشام')\n",
    "plt.hist(data6['length'], alpha = 0.4, bins=bins, label='الشعر الحديث')\n",
    "plt.xlabel('Poem Text Length')\n",
    "plt.ylabel('Numbers')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlim(0,300)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C- poet_name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get binary values for category columns\n",
    "\n",
    "def explode(frame,cat_col,sep=','):\n",
    "    '''inputs-\n",
    "    frame: input dataframe\n",
    "    cat_col: name of the category column\n",
    "    sep: is the seperator between the catgories\n",
    "    \n",
    "    output-\n",
    "    new dataframe with binary values for category columns\n",
    "    '''\n",
    "    df=frame.copy()\n",
    "    df[cat_col]=df[cat_col].apply(lambda x: x.replace(' ',' ').split(sep))\n",
    "    categories=list(set(df[cat_col].sum()))\n",
    "    df_cat=pd.DataFrame(0,index=df.index,columns=categories)\n",
    "    for cat in categories:\n",
    "        df_cat[cat]=df[cat_col].apply(lambda cat_list: int(cat in cat_list))\n",
    "    return pd.concat([df,df_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df=explode(processed_df,'poet_name',sep='/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D- poem_title**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df=explode(processed_df,'poem_title',sep='/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E- poem_text**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Why I did not use the TF (CountVectorizer)? \n",
    "Because counting the number of words in each document will give more weightage to longer documents than shorter documents. To avoid this, I use TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer( min_df=20,ngram_range=(1, 2),lowercase=False)\n",
    "\n",
    "# when I used  integer value for min_df parameters it will choose the cutoff on an absolute value that means\n",
    "# ,for example, the word”Lubna” appears at least 20 times in all documents\n",
    "#scaler = StandardScaler(with_mean=False)\n",
    "#scaler=preprocessing.MaxAbsScaler()\n",
    "\n",
    "\n",
    "\n",
    "# When I used float it means min_df=0.1, for example, the word “Lubna” most be at least appears at 10% of whole\n",
    "# documents\n",
    "\n",
    "\n",
    "#I transformed each text poem into a vector and it's normalize (default by TFIDF)\n",
    "text_poem_df = tfidf_vector.fit_transform(processed_df.poem_text).toarray()\n",
    "labels = processed_df.poet_cat\n",
    "\n",
    "print(\"Each of the %d poem text is represented by %d features (TF-IDF score of unigrams and bigrams)\" %(text_poem_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_poem_df.max() #to ensure its normalized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_df=pd.DataFrame(data=text_poem_df,columns=tfidf_vector.get_feature_names())\n",
    "convert_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check the most popular word in text poem\n",
    "# # text=' '.join(word for word in processed_df.poem_text)\n",
    "\n",
    "# reshaped_texts = arabic_reshaper.reshape(text)\n",
    "# arabic_texts = get_display(reshaped_texts)\n",
    "# # wordcloud=WordCloud( max_words=200).generate(arabic_texts)\n",
    "# # plt.figure(figsize=(10,10))\n",
    "# # plt.imshow(wordcloud)\n",
    "# # plt.axis(\"off\")\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding all features into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df=convert_df.append(processed_df,ignore_index=False,sort=False)\n",
    "#final_df=processed_df+convert_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5.Prepare Train and Test Data sets \n",
    "\n",
    "**Split dataset for training and testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = processed_df.drop(columns=['poet_cat'])\n",
    "X=convert_df\n",
    "y = processed_df.poet_cat.astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.Buliding The Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The classification models build are:**\n",
    "\n",
    "* Random Forest\n",
    "* Linear Support Vector Machine\n",
    "* Multinomial Naive Bayes\n",
    "* K-NN\n",
    "* Logistic Regression\n",
    "\n",
    "The sklearn.pipeline could be used. I proposed to use the mention models, because it has been widely\n",
    "used in related studies, for instance, [Arabic Poetry Authorship Attribution using Machine\n",
    "Learning Techniques](https://thescipub.com/pdf/10.3844/jcssp.2019.1012.1021) and [Machine Learning for Authorship Attribution in Arabic\n",
    "Poetry](https://pdfs.semanticscholar.org/5f6c/9a176f5d4c8d5d48b36051ba61ff75175d7f.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Baseline Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Logistic Regression Model (Baseline Model) with Default Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Logistic Regression Model:')\n",
    "logmodel = LogisticRegression()\n",
    "cross_val=pd.DataFrame(cross_validate(logmodel,X_train,y_train,cv=10,return_train_score=True,scoring=['accuracy','balanced_accuracy', 'f1_weighted']))\n",
    "pd.DataFrame(cross_val.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the above results there is no overfitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Model with Default Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. RandomForest Model with Default Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print('RandomForest Model:')\n",
    "#scorer = make_scorer(f1_score, average = 'weighted')\n",
    "RF_CV = pd.DataFrame(cross_validate(RandomForestClassifier(), X_train, y_train, cv = 10,return_train_score=True,\n",
    "                        scoring = ['accuracy','balanced_accuracy', 'f1_weighted']))\n",
    "pd.DataFrame(RF_CV.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier.roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the above results there is an overfitting so we need to deal with the number of trees (default is 10)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. K-NN Model with Default Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('K-NN Model:')\n",
    "knn= KNeighborsClassifier(n_neighbors=8)\n",
    "knn_croos_val=cross_validate(knn,X_train,y_train,return_train_score=True,cv=10,scoring=['accuracy','balanced_accuracy', 'f1_weighted'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(knn_croos_val).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.  SVM Model with Default Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SVM Model:')\n",
    "SVM=SVC( C=1.0,kernel='linear')\n",
    "SVM_cross_val=cross_validate(SVM, X_train, y_train,return_train_score=False,cv=10,scoring=['accuracy','balanced_accuracy', 'f1_weighted'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(SVM_cross_val.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.Naive Bayes Model with Default Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So they do model slightly different things. If you have discrete multiple features to worry about, \n",
    "you have to use Multinomial NB. But if you only have a single feature to worry about, then you can \n",
    "make a modelling choice based on the above.\n",
    "\n",
    "\n",
    "https://datascience.stackexchange.com/questions/27624/difference-between-bernoulli-and-multinomial-naive-bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to train Naive Bayes Classifier. Naive Bayes Classifier is a good choice given we have a medium sized dataset, NB classifier scales well and also NB classifier has been historically used in NLP tasks. We will train Multinomial and Bernoulli NB classifier, since they almost always outperfrom Gaussian NB classifier in NLP tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB=MultinomialNB()\n",
    "NB_cross_val=pd.DataFrame(cross_validate(NB,X_train,y_train,cv=10,scoring=['accuracy','balanced_accuracy', 'f1_weighted'], return_train_score=True))\n",
    "print(pd.DataFrame(NB_cross_val.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RandomForestClassifier().get_params().keys()  #To get hyperparameters of each classifers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the above results there is no overfitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Models with GridSearchCV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. K-NN Model with Best Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_value=[x for x in range (1,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid_parameters= dict(n_neighbors= k_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score={'balanced_score':make_scorer(metrics.balanced_accuracy_score),'f1_weighted':make_scorer(f1_score, average = 'weighted')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_GridSearchCV=GridSearchCV(estimator=KNeighborsClassifier(), param_grid=knn_grid_parameters,refit='balanced_score',cv=10,scoring=score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_GridSearchCV.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_GridSearchCV.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(knn_GridSearchCV.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_GridSearchCV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. SVM Model with Best Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM=SVC( C=1.0,kernel='sigmoid')\n",
    "\n",
    "SVM_parameters=[{'C':[1,10],'kernel':['linear']},\n",
    "           {'C':[1,10],'kernel':['rbf'], 'gamma':[x for x in np.arange(0.01,0.02,0.01)]}]\n",
    "SVM_GridSearchCV=GridSearchCV(estimator=SVC(), param_grid=SVM_parameters,scoring=score,cv=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_GridSearchCV.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_GridSearchCV.fit (X_train,y_train)\n",
    "SVM_accuracy=SVM_GridSearchCV.best_score_\n",
    "SVM_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_GridSearchCV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  C. RandomForest  Model with Best Hyperparameter ( Selected Model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest_parameters={ \n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "RandomForest_GridSearchCV=GridSearchCV(estimator=RandomForestClassifier(), param_grid=RandomForest_parameters,refit='balanced_score', cv=10,scoring=score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest_GridSearchCV.fit(X_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest_GridSearchCV.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(RandomForest_GridSearchCV.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest_GridSearchCV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RandomForest Model:')\n",
    "RandomForestClassifie=RandomForestClassifier(criterion= 'gini',max_features='auto',n_estimators=100,oob_score=True)\n",
    "RandomForestClassifie.fit(X_train,y_train)\n",
    "#pd.DataFrame(RF_CV1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifie_predication=RandomForestClassifie.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.balanced_accuracy_score(y_test,RandomForestClassifie_predication )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.Series(RandomForestClassifie.feature_importances_,index=X.columns).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a bar plot\n",
    "sns.barplot(x=feature_imp[:5], y=feature_imp.index[:5])\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.legend()\n",
    "plt.figure(figsize=(100,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Logistic Regression Model with Best Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#LogisticRegression().get_params().keys()\n",
    "Logistic_parameters={'C':np.logspace(-3,3,7),'penalty':['l1','l2'] , }\n",
    "Logistic_GridSearchCV=GridSearchCV(estimator=LogisticRegression(), param_grid=Logistic_parameters,refit='balanced_score', cv=10,scoring=score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_GridSearchCV.fit(X_train,y_train)\n",
    "\n",
    "Logistic_GridSearchCV.best_score_\n",
    "\n",
    "Logistic_GridSearchCV.best_estimator_\n",
    "\n",
    "Logistic_GridSearchCV.best_params_\n",
    "\n",
    "pd.DataFrame(Logistic_GridSearchCV.cv_results_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### E. Naive Bayes Model with Best Hyperparameter\n",
    "\n",
    "https://stackoverflow.com/questions/39828535/how-to-tune-guassiannb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.Evaluating The Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_ConfusionMatrix = pd.DataFrame(confusion_matrix(y_test,RandomForestClassifie_predication))\n",
    "#knn_ConfusionMatrix = confusion_matrix(y_test,knn_predictions)\n",
    "\n",
    "\n",
    "\n",
    "print('The Confusion Matrix for Random Forest Model is :','\\n')\n",
    "\n",
    "#print('\\n The Confusion Matrix for K-NN Model is :','\\n',knn_ConfusionMatrix)\n",
    "RF_ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,RandomForestClassifie_predication))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(y_test,RandomForestClassifie_predication , average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, a classification model built to classify Arabic poetry based on the poet's origin. We have applied multiple empirical experiments on the poems dataset scraped from the [Adab website]( http://adab.com/) to test our models. Overall, our results were assessed thoroughly by applying the most commonly used measures for multi-text classification problems, which are (F1-weighted and balanced_score) evaluation measures. TF-IDF vectorization approache were uesed, other approaches such as FastText and doc2vec could be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resource of some errors faced during project: \n",
    "\n",
    "* Errors of the direction of the Arabic text\n",
    "\n",
    "! pip install python-bidi\n",
    "! pip install arabic_reshaper\n",
    "Python3 is no needed for decode value\n",
    "\n",
    "[source](https://stackoverflow.com/questions/47057509/arabic-text-in-matplotlib?rq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
